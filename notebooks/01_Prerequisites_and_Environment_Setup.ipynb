{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afc2de71",
   "metadata": {},
   "source": [
    "# ðŸ“— 01Â â€” PrerequisitesÂ &Â EnvironmentÂ Setup\n",
    "\n",
    "> **Mission:** walk stepâ€‘byâ€‘step through every installation and validation task required for this RAG workshop.  \n",
    "\n",
    "**Supported OS:** macOSÂ (AppleÂ &Â Intel) â€¢ WindowsÂ 10/11 â€¢ Linux (Ubuntu/Debian).  \n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ—ºÂ Roadmap\n",
    "\n",
    "1. Check / install PythonÂ 3.11â€¯+  \n",
    "2. Install Docker Desktop  \n",
    "3. Install fast tooling (`uv`,Â `ruff`)  \n",
    "4. Clone the course repo  \n",
    "5. Create & activate a virtualâ€‘env  \n",
    "6. Install course dependencies  \n",
    "7. Pull & run services (OpenSearchÂ + Dashboards + Ollama)  \n",
    "8. Create `constants.py`  \n",
    "9. Verify docTR OCR  \n",
    "10. Sanityâ€‘check all services  \n",
    "\n",
    "*(Total handsâ€‘on time:Â â‰ˆâ€¯25Â minutes on a decent connection)*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42334136",
   "metadata": {},
   "source": [
    "## 1Â â€”Â PythonÂ 3.11Â or newer ðŸ\n",
    "\n",
    "Guide - https://realpython.com/installing-python/\n",
    "\n",
    "#### macOS\n",
    "\n",
    "```bash\n",
    "# Homebrew (recommended)\n",
    "brew install python@3.12\n",
    "echo 'export PATH=\"/opt/homebrew/opt/python@3.12/libexec/bin:$PATH\"' >> ~/.zshrc\n",
    "source ~/.zshrc\n",
    "\n",
    "which python3.12  \n",
    "python3 --version \n",
    "\n",
    "```\n",
    "#### WindowsÂ 10/11\n",
    "\n",
    "```powershell\n",
    "# Winget\n",
    "winget install Python.Python.3.12\n",
    "# OR Microsoft Store: \"PythonÂ 3.12\"\n",
    "\n",
    "python3 --version \n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c8aa11",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1.2 â€”Â Install `uv`\n",
    "\n",
    "Document - https://docs.astral.sh/uv/getting-started/installation/#standalone-installer\n",
    "\n",
    "#### macOS / Linux (bashÂ / zsh)\n",
    "\n",
    "```bash\n",
    "curl -LsSf https://astral.sh/uv/install.sh | less\n",
    "\n",
    "brew install uv \n",
    "```\n",
    "\n",
    "#### WindowsÂ (PowerShell)\n",
    "\n",
    "```powershell\n",
    "python3 -m pip install uv \n",
    "\n",
    "py -m pip install -U uv \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f88d4b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1.3 Create, Activate & Register a `uv` Kernel ðŸ\n",
    "\n",
    "We will create an isolated environment for this course using `uv` and then register it as a kernel so Jupyter can use it.\n",
    "\n",
    "**Run these commands in your terminal**, from the `build_your_local_RAG_system` folder.\n",
    "\n",
    "#### 1.3.1 Create & Activate\n",
    "\n",
    "```bash\n",
    "# Create a virtual env using Python 3.12\n",
    "uv venv -p python3.12 .venv\n",
    "\n",
    "# Activate it (your prompt should get a (.venv) prefix)\n",
    "source .venv/bin/activate\n",
    "```\n",
    "\n",
    "> **Windows Users?**  \n",
    "> Use `.venv\\Scripts\\Activate.ps1` (PowerShell) or `.venv\\Scripts\\activate.bat` (CMD) to activate.\n",
    "\n",
    "#### 1.3.2 Install & Register Kernel\n",
    "\n",
    "```bash\n",
    "# Install the kernel package into our new env\n",
    "uv pip install ipykernel\n",
    "```\n",
    "\n",
    "#### 1.3.3 Select the Kernel in This Notebook\n",
    "\n",
    "**Restart your Jupyter server now.**\n",
    "\n",
    "Once it reloads, click here in the notebook and select from the top menu:\n",
    "\n",
    "`Kernel` â†’ `Change kernel` â†’ `RAG Course (Python 3.12)`\n",
    "\n",
    "After selecting it, the final check below should pass.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af2b4bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"python_version\": \"3.12.11\",\n",
      "  \"ok\": true\n",
      "}\n",
      "Python version is sufficient\n"
     ]
    }
   ],
   "source": [
    "import sys, json\n",
    "py_ok = sys.version_info >= (3,11)\n",
    "print(json.dumps({\n",
    "    \"python_version\": sys.version.split()[0],\n",
    "    \"ok\": py_ok\n",
    "}, indent=2))\n",
    "assert py_ok, \"Python <3.11 â€” install a newer version before continuing\"\n",
    "print(\"Python version is sufficient\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067044fd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2Â â€”Â Install Course Dependencies ðŸ“¦\n",
    "\n",
    "```bash\n",
    "uv pip install -r requirements.txt               # main deps\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d58e4df",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3Â â€”Â Docker Desktop ðŸ³\n",
    "\n",
    "Download & install:\n",
    "\n",
    "* **macOS (Apple/Intel):** <https://www.docker.com/products/docker-desktop/>\n",
    "* **WindowsÂ 10/11:** same link (WSLÂ 2 required)\n",
    "* **Linux:** `sudo apt install docker.io docker-compose-plugin`\n",
    "\n",
    "After installation **reboot** or at least restart your terminal so the `docker` command is on yourÂ PATH.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dd831ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"docker_cmd\": \"/usr/local/bin/docker\",\n",
      "  \"version\": \"Docker version 28.3.2, build 578ccf6\"\n",
      "}\n",
      "âœ… Docker CLI found\n"
     ]
    }
   ],
   "source": [
    "import subprocess, shutil, json\n",
    "docker_path = shutil.which(\"docker\")\n",
    "if not docker_path:\n",
    "    raise RuntimeError(\"ðŸš¨ 'docker' command not found. Finish Docker install & restart terminal.\")\n",
    "ver = subprocess.check_output([\"docker\", \"--version\"], text=True)\n",
    "print(json.dumps({\"docker_cmd\": docker_path, \"version\": ver.strip()}, indent=2))\n",
    "print(\"âœ… Docker CLI found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2cfea3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4Â â€”Â Install Ollama\n",
    "\n",
    "Download & install:\n",
    "\n",
    "* https://ollama.com/download\n",
    "\n",
    "\n",
    "Lets download Qwen3 model:\n",
    "\n",
    "\n",
    "* https://ollama.com/library/qwen3\n",
    "\n",
    "```bash\n",
    "ollama run qwen3:8b \n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc96046",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5Â â€”Â Pull & Run Core Services \n",
    "\n",
    "### 5.1Â OpenSearchÂ (singleâ€‘node)\n",
    "\n",
    "```bash\n",
    "docker pull opensearchproject/opensearch:2.19.2\n",
    "docker pull opensearchproject/opensearch-dashboards:2.19.2\n",
    "\n",
    "docker run -d --name opensearch \\\n",
    "  -p 9200:9200 -p 9600:9600 \\\n",
    "  -e \"discovery.type=single-node\" \\\n",
    "  -e \"DISABLE_SECURITY_PLUGIN=true\" \\\n",
    "  opensearchproject/opensearch:2.19.2\n",
    "\n",
    "docker run -d --name opensearch-dashboards \\\n",
    "  -p 5601:5601 \\\n",
    "  --link opensearch:opensearch \\\n",
    "  -e \"OPENSEARCH_HOSTS=http://opensearch:9200\" \\\n",
    "  -e \"DISABLE_SECURITY_DASHBOARDS_PLUGIN=true\" \\\n",
    "  opensearchproject/opensearch-dashboards:2.19.2\n",
    "```\n",
    "\n",
    "\n",
    "> Visit http://localhost:5601 in your browser to access the OpenSearch Dashboard. If you see the dashboard, youâ€™re all set! ðŸŽ‰\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc13be4",
   "metadata": {},
   "source": [
    "### 5.2 Add Hybrid functionality to OpenSearch\n",
    "\n",
    " > Open the OpenSearch Dashboard, go to Dev Tools, paste the below JSON, and hit Run. This pipeline will be essential for blending the BM25 and semantic scores for improved search quality.\n",
    "\n",
    "json\n",
    "```\n",
    "PUT /_search/pipeline/nlp-search-pipeline\n",
    "{\n",
    "  \"description\": \"Post processor for hybrid search\",\n",
    "  \"phase_results_processors\": [\n",
    "    {\n",
    "      \"normalization-processor\": {\n",
    "        \"normalization\": {\n",
    "          \"technique\": \"min_max\"\n",
    "        },\n",
    "        \"combination\": {\n",
    "          \"technique\": \"arithmetic_mean\",\n",
    "          \"parameters\": {\n",
    "            \"weights\": [\n",
    "              0.3,\n",
    "              0.7\n",
    "            ]\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd0da6c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6Â â€”Â Install and Verify OCR Engine (Tesseract)\n",
    "\n",
    "For our OCR tasks, we will use `pytesseract`, a Python wrapper for Google's Tesseract-OCR engine. This requires a two-part setup: first installing the engine on your operating system, and then installing the Python library that connects to it.\n",
    "\n",
    "### 6.1 Install External Dependencies (Tesseract & Poppler)\n",
    "\n",
    "`pytesseract` needs **Tesseract** to read characters, and its helper library `pdf2image` needs **Poppler** to convert PDF pages into images. You must install both.\n",
    "\n",
    "#### **macOS (via Homebrew)**\n",
    "\n",
    "Open your terminal and run this single command:\n",
    "```bash\n",
    "brew install tesseract poppler\n",
    "```\n",
    "\n",
    "#### **Windows**\n",
    "\n",
    "1.  **Install Tesseract:**\n",
    "    *   Download the official installer from the [Tesseract at UB Mannheim page](https://github.com/UB-Mannheim/tesseract/wiki).\n",
    "    *   Run the installer. **Important:** Take note of the installation path, which is usually `C:\\Program Files\\Tesseract-OCR`.\n",
    "    or\n",
    "    winget install Tesseract-OCR\n",
    "\n",
    "2.  **Install Poppler:**\n",
    "    *   Download the latest Poppler binary from [this GitHub repository](https://github.com/oschwartz/poppler-for-windows/releases/).\n",
    "    *   Unzip the file into a permanent location, like `C:\\poppler`.\n",
    "    *   Add the `bin` subfolder (e.g., `C:\\poppler\\poppler-24.02.0\\bin`) to your system's PATH environment variable.\n",
    "    Guide - https://github.com/oschwartz10612/poppler-windows/issues/42\n",
    "\n",
    "### 6.2 Install Python Libraries\n",
    "\n",
    "With the external tools installed, now install the Python libraries into your active virtual environment.\n",
    "\n",
    "```bash\n",
    "uv pip install pytesseract pdf2image Pillow fpdf2\n",
    "```\n",
    "> We install `fpdf2` just to create a dummy PDF for the test below.\n",
    "\n",
    "### 6.3 Run Verification Test\n",
    "\n",
    "The final step is to run the code cell below. It will:\n",
    "1.  Create a simple, one-page PDF file named `ocr_test.pdf`.\n",
    "2.  Use `pdf2image` and `pytesseract` to read the text from it.\n",
    "3.  Print the extracted text and a success message.\n",
    "\n",
    "> **Note for Windows Users:** You may need to uncomment and set the `tesseract_cmd` path in the code below if it's not found automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "145c4415",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4ac2ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your PDF\n",
    "pdf_path = \"climate.pdf\"\n",
    "\n",
    "# Convert PDF to images\n",
    "images = convert_from_path(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cc4ae57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=1700x2200>,\n",
       " <PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=1700x2200>,\n",
       " <PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=1700x2200>,\n",
       " <PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=1700x2200>,\n",
       " <PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=1700x2200>,\n",
       " <PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=1700x2200>,\n",
       " <PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=1700x2200>,\n",
       " <PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=1700x2200>,\n",
       " <PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=1700x2200>,\n",
       " <PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=1700x2200>,\n",
       " <PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=1700x2200>,\n",
       " <PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=1700x2200>,\n",
       " <PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=1700x2200>,\n",
       " <PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=1700x2200>,\n",
       " <PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=1700x2200>,\n",
       " <PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=1700x2200>,\n",
       " <PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=1700x2200>,\n",
       " <PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=1700x2200>,\n",
       " <PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=1700x2200>,\n",
       " <PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=1700x2200>,\n",
       " <PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=1700x2200>,\n",
       " <PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=1700x2200>,\n",
       " <PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=1700x2200>,\n",
       " <PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=1700x2200>,\n",
       " <PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=1700x2200>,\n",
       " <PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=1700x2200>,\n",
       " <PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=1700x2200>,\n",
       " <PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=1700x2200>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98354dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Page 1 ---\n",
      "\n",
      "[Tesseract OCR]\n",
      "Summary\n",
      "for Policymakers\n",
      "\n",
      "Drafting Authors:\n",
      "\n",
      "Lisa V. Alexander (Australia), Simon K. Allen (Switzerland/New Zealand), Nathaniel L. Bindoff\n",
      "(Australia), Frangois-Marie BrÃ©on (France), John A. Church (Australia), Ulrich Cubasch\n",
      "(Germany), Seita Emori (Japan), Piers Forster (UK), Pierre Friedlingstein (UK/Belgium), Nathan\n",
      "Gillett (Canada), Jonathan M. Gregory (UK), Dennis L. Hartmann (USA), Eystein Jansen\n",
      "(Norway), Ben Kirtman (USA), Reto Knutti (Switzerland), Krishna Kumar Kanikicharla (India),\n",
      "Peter Lemke (Germany), Jochem Marotzke (Germany), ValÃ©rie Masson-Delmotte (France),\n",
      "Gerald A. Meehl (USA), Igor I. Mokhov (Russian Federation), Shilong Piao (China), Gian-Kasper\n",
      "Plattner (Switzerland), Qin Dahe (China), Venkatachalam Ramaswamy (USA), David Randall\n",
      "(USA), Monika Rhein (Germany), Maisa Rojas (Chile), Christopher Sabine (USA), Drew Shindell\n",
      "(USA), Thomas F. Stocker (Switzerland), Lynne D. Talley (USA), David G. Vaughan (UK), Shang-\n",
      "Ping Xie (USA)\n",
      "\n",
      "Draft Contributing Authors:\n",
      "\n",
      "Myles R.Allen (UK), Olivier Boucher (France), Don Chambers (USA), Jens Hesselbjerg Christensen\n",
      "(Denmark), Philippe Ciais (France), Peter U. Clark (USA), Matthew Collins (UK), Josefino C.\n",
      "Comiso (USA), Viviane Vasconcellos de Menezes (Australia/Brazil), Richard A. Feely (USA),\n",
      "Thierry Fichefet (Belgium), Arlene M. Fiore (USA), Gregory Flato (Canada), Jan Fuglestvedt\n",
      "(Norway), Gabriele Hegerl (UK/Germany), Paul J. Hezel (Belgium/USA), Gregory C. Johnson\n",
      "(USA), Georg Kaser (Austria/Italy), Vladimir Kattsov (Russian Federation), John Kennedy (UK),\n",
      "Albert M. G. Klein Tank (Netherlands), Corinne Le QuÃ©rÃ© (UK), Gunnar Myhre (Norway), Timothy\n",
      "Osborn (UK), Antony J. Payne (UK), Judith Perlwitz (USA), Scott Power (Australia), Michael\n",
      "Prather (USA), Stephen R. Rintoul (Australia), Joeri Rogelj (Switzerland/Belgium), Matilde\n",
      "Rusticucci (Argentina), Michael Schulz (Germany), Jan Sedlacek (Switzerland), Peter A. Stott\n",
      "(UK), Rowan Sutton (UK), Peter W. Thorne (USA/Norway/UK), Donald Wuebbles (USA)\n",
      "\n",
      "This Summary for Policymakers should be cited as:\n",
      "\n",
      "IPCC, 2013: Summary for Policymakers. In: Climate Change 2013: The Physical Science Basis. Contribution of\n",
      "Working Group | to the Fifth Assessment Report of the Intergovernmental Panel on Climate Change [Stocker,\n",
      "TF, D. Qin, G.-K. Plattner, M. Tignor, S.K. Allen, J. Boschung, A. Nauels, Y. Xia, V. Bex and P.M. Midgley (eds.)].\n",
      "Cambridge University Press, Cambridge, United Kingdom and New York, NY, USA.\n",
      "\n",
      "--- Page 2 ---\n",
      "\n",
      "[Tesseract OCR]\n",
      "Summary for Policymakers\n",
      "\n",
      "A. Introduction\n",
      "\n",
      "The Working Group | contribution to the IPCCâ€™s Fifth Assessment Report (AR5) considers new evidence of climate change\n",
      "based on many independent scientific analyses from observations of the climate system, paleoclimate archives, theoretical\n",
      "studies of climate processes and simulations using climate models. It builds upon the Working Group | contribution to the\n",
      "IPCC's Fourth Assessment Report (AR4), and incorporates subsequent new findings of research. As a component of the\n",
      "fifth assessment cycle, the IPCC Special Report on Managing the Risks of Extreme Events and Disasters to Advance Climate\n",
      "Change Adaptation (SREX) is an important basis for information on changing weather and climate extremes.\n",
      "\n",
      "This Summary for Policymakers (SPM) follows the structure of the Working Group | report. The narrative is supported by a\n",
      "series of overarching highlighted conclusions which, taken together, provide a concise summary. Main sections are introduced\n",
      "with a brief paragraph in italics which outlines the methodological basis of the assessment.\n",
      "\n",
      "The degree of certainty in key findings in this assessment is based on the author teamsâ€™ evaluations of underlying scientific\n",
      "understanding and is expressed as a qualitative level of confidence (from very low to very high) and, when possible,\n",
      "probabilistically with a quantified likelihood (from exceptionally unlikely to virtually certain). Confidence in the validity of\n",
      "a finding is based on the type, amount, quality, and consistency of evidence (e.g., data, mechanistic understanding, theory,\n",
      "models, expert judgment) and the degree of agreement'. Probabilistic estimates of quantified measures of uncertainty in a\n",
      "finding are based on statistical analysis of observations or model results, or both, and expert judgment?. Where appropriate,\n",
      "findings are also formulated as statements of fact without using uncertainty qualifiers. (See Chapter 1 and Box TS.1 for more\n",
      "details about the specific language the IPCC uses to communicate uncertainty).\n",
      "\n",
      "The basis for substantive paragraphs in this Summary for Policymakers can be found in the chapter sections of the underlying\n",
      "report and in the Technical Summary. These references are given in curly brackets.\n",
      "\n",
      "B. Observed Changes in the Climate System\n",
      "\n",
      "Observations of the climate system are based on direct measurements and remote sensing from satellites and other platforms.\n",
      "Global-scale observations from the instrumental era began in the mid-19th century for temperature and other variables, with\n",
      "more comprehensive and diverse sets of observations available for the period 1950 onwards. Paleoclimate reconstructions\n",
      "extend some records back hundreds to millions of years. Together, they provide a comprehensive view of the variability and\n",
      "long-term changes in the atmosphere, the ocean, the cryosphere, and the land surface.\n",
      "\n",
      "Warming of the climate system is unequivocal, and since the 1950s, many of the observed\n",
      "changes are unprecedented over decades to millennia. The atmosphere and ocean have\n",
      "warmed, the amounts of snow and ice have diminished, sea level has risen, and the\n",
      "concentrations of greenhouse gases have increased (see Figures SPM.1, SPM.2, SPM.3 and\n",
      "SPM.A). {2.2, 2.4, 3.2, 3.7, 4.2-4.7, 5.2, 5.3, 5.5-5.6, 6.2, 13.2}\n",
      "\n",
      "1 In this Summary for Policymakers, the following summary terms are used to describe the available evidence: limited, medium, or robust; and for the degree of agreement:\n",
      "\n",
      "low, medium, or high. A level of confidence is expressed using five qualifiers: very low, low, medium, high, and very high, and typeset in italics, e.g., medium confidence\n",
      "For a given evidence and agreement statement, different confidence levels can be assigned, but increasing levels of evidence and degrees of agreement are correlated with\n",
      "increasing confidence (see Chapter 1 and Box TS.1 for more details)\n",
      "\n",
      "2 In this Summary for Policymakers, the following terms have been used to indicate the assessed likelihood of an outcome or a result: virtually certain 99-100% probability,\n",
      "very likely 90-100%, likely 66â€”100%, about as likely as not 33-66%, unlikely 0-33%, very unlikely 0-10%, exceptionally unlikely 0Q-1%. Additional terms (extremely likely:\n",
      "95-100%, more likely than not >50-100%, and extremely unlikely 0-5%) may also be used when appropriate. Assessed likelihood is typeset in italics, e.g., very likely (see\n",
      "Chapter 1 and Box TS.1 for more details).\n",
      "\n",
      "--- Page 3 ---\n",
      "\n",
      "[Tesseract OCR]\n",
      "Summary for Policymakers\n",
      "\n",
      "B.1 Atmosphere\n",
      "\n",
      "Each of the last three decades has been successively warmer at the Earthâ€™s surface than any\n",
      "preceding decade since 1850 (see Figure SPM.1). In the Northern Hemisphere, 1983-2012\n",
      "was likely the warmest 30-year period of the last 1400 years (medium confidence). {2.4, 5.3}\n",
      "\n",
      "Â¢ The globally averaged combined land and ocean surface temperature data as calculated by a linear trend, show a\n",
      "warming of 0.85 [0.65 to 1.06] Â°C?, over the period 1880 to 2012, when multiple independently produced datasets exist.\n",
      "The total increase between the average of the 1850-1900 period and the 2003-2012 period is 0.78 [0.72 to 0.85] Â°C,\n",
      "based on the single longest dataset availableâ€˜ (see Figure SPM.1). {2.4}\n",
      "\n",
      "e For the longest period when calculation of regional trends is sufficiently complete (1901 to 2012), almost the entire globe\n",
      "has experienced surface warming (see Figure SPM.1). {2.4}\n",
      "\n",
      "e In addition to robust multi-decadal warming, global mean surface temperature exhibits substantial decadal and\n",
      "\n",
      "interannual variability (see Figure SPM.1). Due to natural variability, trends based on short records are very sensitive to\n",
      "the beginning and end dates and do not in general reflect long-term climate trends. As one example, the rate of warming\n",
      "over the past 15 years (1998-2012; 0.05 [-0.05 to 0.15] Â°C per decade), which begins with a strong El Nifio, is smaller\n",
      "than the rate calculated since 1951 (1951-2012; 0.12 [0.08 to 0.14] Â°C per decade)>. {2.4}\n",
      "\n",
      "Â©  Continental-scale surface temperature reconstructions show, with high confidence, multi-decadal periods during\n",
      "the Medieval Climate Anomaly (year 950 to 1250) that were in some regions as warm as in the late 20th century.\n",
      "These regional warm periods did not occur as coherently across regions as the warming in the late 20th century (high\n",
      "confidence). {5.5}\n",
      "\n",
      "e It is virtually certain that globally the troposphere has warmed since the mid-20th century. More complete observations\n",
      "allow greater confidence in estimates of tropospheric temperature changes in the extratropical Northern Hemisphere\n",
      "than elsewhere. There is medium confidence in the rate of warming and its vertical structure in the Northern Hemisphere\n",
      "extra-tropical troposphere and /ow confidence elsewhere. {2.4}\n",
      "\n",
      "Â© Confidence in precipitation change averaged over global land areas since 1901 is /ow prior to 1951 and medium\n",
      "afterwards. Averaged over the mid-latitude land areas of the Northern Hemisphere, precipitation has increased since\n",
      "1901 (medium confidence before and high confidence after 1951). For other latitudes area-averaged long-term positive\n",
      "or negative trends have low confidence (see Figure SPM.2). {TS TFE.1, Figure 2; 2.5}\n",
      "\n",
      "Â¢ Changes in many extreme weather and climate events have been observed since about 1950 (see Table SPM.1 for\n",
      "details). It is very likely that the number of cold days and nights has decreased and the number of warm days and nights\n",
      "has increased on the global scaleÂ®. It is likely that the frequency of heat waves has increased in large parts of Europe,\n",
      "Asia and Australia. There are /ikely more land regions where the number of heavy precipitation events has increased than\n",
      "where it has decreased. The frequency or intensity of heavy precipitation events has /ikely increased in North America and\n",
      "Europe. In other continents, confidence in changes in heavy precipitation events is at most medium. {2.6}\n",
      "\n",
      "3 In the WGI contribution to the ARS, uncertainty is quantified using 90% uncertainty intervals unless otherwise stated. The 90% uncertainty interval, reported in square\n",
      "brackets, is expected to have a 90% likelihood of covering the value that is being estimated. Uncertainty intervals are not necessarily symmetric about the corresponding\n",
      "best estimate. A best estimate of that value is also given where available.\n",
      "\n",
      "4 Both methods presented in this bullet were also used in AR4. The first calculates the difference using a best fit linear trend of all points between 1880 and 2012. The second\n",
      "calculates the difference between averages for the two periods 1850-1900 and 2003-2012. Therefore, the resulting values and their 90% uncertainty intervals are not\n",
      "directly comparable. {2.4}\n",
      "\n",
      "5 Trends for 15-year periods starting in 1995, 1996, and 1997 are 0.13 [0.02 to 0.24] Â°C per decade, 0.14 [0.03 to 0.24] Â°C per decade, and, 0.07 [-0.02 to 0.18] Â°C per\n",
      "decade, respectively.\n",
      "\n",
      "Â® â€” See the Glossary for the definition of these terms: cold days/cold nights, warm days/warm nights, heat waves.\n",
      "\n",
      "--- Page 4 ---\n",
      "\n",
      "[Tesseract OCR]\n",
      "Summary for Policymakers\n",
      "\n",
      "Observed globally averaged combined land and ocean\n",
      "(a) surface temperature anomaly 1850-2012\n",
      "\n",
      "Annual average\n",
      "\n",
      "Decadal average\n",
      "\n",
      "Temperature anomaly (Â°C) relative to 1961-1990\n",
      "\n",
      "= 7\n",
      "1850 1900 1950 2000\n",
      "Year\n",
      "(b) Observed change in surface temperature 1901-2012\n",
      "\n",
      "-06 -04 -0.2 0 02 04 06 08 10 125 15 175 25\n",
      "(Â°C)\n",
      "\n",
      "Figure SPM.1 | (a) Observed global mean combined land and ocean surface temperature anomalies, from 1850 to 2012 from three data sets. Top panel:\n",
      "annual mean values. Bottom panel: decadal mean values including the estimate of uncertainty for one dataset (black). Anomalies are relative to the mean\n",
      "of 1961-1990. (b) Map of the observed surface temperature change from 1901 to 2012 derived from temperature trends determined by linear regression\n",
      "from one dataset (orange line in panel a). Trends have been calculated where data availability permits a robust estimate (i.e., only for grid boxes with\n",
      "greater than 70% complete records and more than 20% data availability in the first and last 10% of the time period). Other areas are white. Grid boxes\n",
      "where the trend is significant at the 10% level are indicated by a + sign. Fora listing of the datasets and further technical details see the Technical Summary\n",
      "Supplementary Material. {Figures 2.19-2.21; Figure TS.2}\n",
      "\n",
      "--- Page 5 ---\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Page \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# ----- Tesseract OCR -----\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m text_tesseract = \u001b[43mpytesseract\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimage_to_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m[Tesseract OCR]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(text_tesseract.strip())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/rag_apps/build_your_local_RAG_system/.venv/lib/python3.12/site-packages/pytesseract/pytesseract.py:486\u001b[39m, in \u001b[36mimage_to_string\u001b[39m\u001b[34m(image, lang, config, nice, output_type, timeout)\u001b[39m\n\u001b[32m    481\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[33;03mReturns the result of a Tesseract OCR run on the provided image to string\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    484\u001b[39m args = [image, \u001b[33m'\u001b[39m\u001b[33mtxt\u001b[39m\u001b[33m'\u001b[39m, lang, config, nice, timeout]\n\u001b[32m--> \u001b[39m\u001b[32m486\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m{\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mBYTES\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDICT\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSTRING\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m[\u001b[49m\u001b[43moutput_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/rag_apps/build_your_local_RAG_system/.venv/lib/python3.12/site-packages/pytesseract/pytesseract.py:489\u001b[39m, in \u001b[36mimage_to_string.<locals>.<lambda>\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    481\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[33;03mReturns the result of a Tesseract OCR run on the provided image to string\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    484\u001b[39m args = [image, \u001b[33m'\u001b[39m\u001b[33mtxt\u001b[39m\u001b[33m'\u001b[39m, lang, config, nice, timeout]\n\u001b[32m    486\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    487\u001b[39m     Output.BYTES: \u001b[38;5;28;01mlambda\u001b[39;00m: run_and_get_output(*(args + [\u001b[38;5;28;01mTrue\u001b[39;00m])),\n\u001b[32m    488\u001b[39m     Output.DICT: \u001b[38;5;28;01mlambda\u001b[39;00m: {\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m: run_and_get_output(*args)},\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     Output.STRING: \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    490\u001b[39m }[output_type]()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/rag_apps/build_your_local_RAG_system/.venv/lib/python3.12/site-packages/pytesseract/pytesseract.py:352\u001b[39m, in \u001b[36mrun_and_get_output\u001b[39m\u001b[34m(image, extension, lang, config, nice, timeout, return_bytes)\u001b[39m\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m save(image) \u001b[38;5;28;01mas\u001b[39;00m (temp_name, input_filename):\n\u001b[32m    342\u001b[39m     kwargs = {\n\u001b[32m    343\u001b[39m         \u001b[33m'\u001b[39m\u001b[33minput_filename\u001b[39m\u001b[33m'\u001b[39m: input_filename,\n\u001b[32m    344\u001b[39m         \u001b[33m'\u001b[39m\u001b[33moutput_filename_base\u001b[39m\u001b[33m'\u001b[39m: temp_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    349\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m'\u001b[39m: timeout,\n\u001b[32m    350\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m352\u001b[39m     \u001b[43mrun_tesseract\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    353\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _read_output(\n\u001b[32m    354\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs[\u001b[33m'\u001b[39m\u001b[33moutput_filename_base\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mextsep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mextension\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    355\u001b[39m         return_bytes,\n\u001b[32m    356\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/rag_apps/build_your_local_RAG_system/.venv/lib/python3.12/site-packages/pytesseract/pytesseract.py:282\u001b[39m, in \u001b[36mrun_tesseract\u001b[39m\u001b[34m(input_filename, output_filename_base, extension, lang, config, nice, timeout)\u001b[39m\n\u001b[32m    279\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    280\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m TesseractNotFoundError()\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtimeout_manager\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43merror_string\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreturncode\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mraise\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mTesseractError\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreturncode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_errors\u001b[49m\u001b[43m(\u001b[49m\u001b[43merror_string\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.11-macos-aarch64-none/lib/python3.12/contextlib.py:137\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args, \u001b[38;5;28mself\u001b[39m.kwds, \u001b[38;5;28mself\u001b[39m.func\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mgenerator didn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt yield\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/rag_apps/build_your_local_RAG_system/.venv/lib/python3.12/site-packages/pytesseract/pytesseract.py:144\u001b[39m, in \u001b[36mtimeout_manager\u001b[39m\u001b[34m(proc, seconds)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m seconds:\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m    145\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.11-macos-aarch64-none/lib/python3.12/subprocess.py:1209\u001b[39m, in \u001b[36mPopen.communicate\u001b[39m\u001b[34m(self, input, timeout)\u001b[39m\n\u001b[32m   1206\u001b[39m     endtime = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1208\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1209\u001b[39m     stdout, stderr = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1210\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1211\u001b[39m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[32m   1212\u001b[39m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[32m   1213\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.11-macos-aarch64-none/lib/python3.12/subprocess.py:2115\u001b[39m, in \u001b[36mPopen._communicate\u001b[39m\u001b[34m(self, input, endtime, orig_timeout)\u001b[39m\n\u001b[32m   2108\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_timeout(endtime, orig_timeout,\n\u001b[32m   2109\u001b[39m                         stdout, stderr,\n\u001b[32m   2110\u001b[39m                         skip_check_and_raise=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   2111\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(  \u001b[38;5;66;03m# Impossible :)\u001b[39;00m\n\u001b[32m   2112\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m_check_timeout(..., skip_check_and_raise=True) \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   2113\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mfailed to raise TimeoutExpired.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2115\u001b[39m ready = \u001b[43mselector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2116\u001b[39m \u001b[38;5;28mself\u001b[39m._check_timeout(endtime, orig_timeout, stdout, stderr)\n\u001b[32m   2118\u001b[39m \u001b[38;5;66;03m# XXX Rewrite these to use non-blocking I/O on the file\u001b[39;00m\n\u001b[32m   2119\u001b[39m \u001b[38;5;66;03m# objects; they are no longer using C stdio!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.11-macos-aarch64-none/lib/python3.12/selectors.py:415\u001b[39m, in \u001b[36m_PollLikeSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    413\u001b[39m ready = []\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m     fd_event_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    417\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for i, img in enumerate(images):\n",
    "    print(f\"\\n--- Page {i+1} ---\\n\")\n",
    "    \n",
    "    # ----- Tesseract OCR -----\n",
    "    text_tesseract = pytesseract.image_to_string(img)\n",
    "    print(\"[Tesseract OCR]\")\n",
    "    print(text_tesseract.strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
